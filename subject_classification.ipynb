{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " business\n",
      "\n",
      " entertainment\n",
      "\n",
      " food\n",
      "\n",
      " graphics\n",
      "\n",
      " historical\n",
      "\n",
      " medical\n",
      "\n",
      " politics\n",
      "\n",
      " space\n",
      "\n",
      " sport\n",
      "\n",
      " technologie\n"
     ]
    }
   ],
   "source": [
    "#read the files form the folder\n",
    "input_path = \"C:/Users/ramna/DataScience/IR/Search_Engine-7071CEM/subject_Classification\"\n",
    "df_cat = pd.DataFrame(columns=['Details','File Name','Info'])\n",
    "\n",
    "category_details =[]\n",
    "files_details =[]\n",
    "data_details = []\n",
    "\n",
    "for details in os.listdir(input_path):\n",
    "    print(\"\\n\",details)\n",
    "    subfolder_path = os.path.join(input_path,details)\n",
    "    for files in os.listdir(subfolder_path):\n",
    "        file_path = os.path.join(subfolder_path,files)\n",
    "        \n",
    "        #print(file_path)\n",
    "        category_details.append(details)\n",
    "        files_details.append(files)\n",
    "        file_ptr = open(file_path, encoding=\"utf8\")\n",
    "        data = file_ptr.read().split('\\n')\n",
    "        data=list(filter(None, data))\n",
    "        #data = data.split(' ')\n",
    "        data_details.append(data)\n",
    "        \n",
    "df_cat['Details'] = category_details\n",
    "df_cat['File Name'] = files_details\n",
    "df_cat['Info']  = data_details    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Details</th>\n",
       "      <th>File Name</th>\n",
       "      <th>Info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>business</td>\n",
       "      <td>business_1.txt</td>\n",
       "      <td>[Lufthansa flies back to profit, German airlin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>business_10.txt</td>\n",
       "      <td>[Winn-Dixie files for bankruptcy, US supermark...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>business</td>\n",
       "      <td>business_100.txt</td>\n",
       "      <td>[US economy still growing says Fed, Most areas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>business</td>\n",
       "      <td>business_11.txt</td>\n",
       "      <td>[Saab to build Cadillacs in Sweden, General Mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>business</td>\n",
       "      <td>business_12.txt</td>\n",
       "      <td>[Bank voted 8-1 for no rate change, The decisi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Details         File Name  \\\n",
       "0  business    business_1.txt   \n",
       "1  business   business_10.txt   \n",
       "2  business  business_100.txt   \n",
       "3  business   business_11.txt   \n",
       "4  business   business_12.txt   \n",
       "\n",
       "                                                Info  \n",
       "0  [Lufthansa flies back to profit, German airlin...  \n",
       "1  [Winn-Dixie files for bankruptcy, US supermark...  \n",
       "2  [US economy still growing says Fed, Most areas...  \n",
       "3  [Saab to build Cadillacs in Sweden, General Mo...  \n",
       "4  [Bank voted 8-1 for no rate change, The decisi...  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "politics         100\n",
       "food             100\n",
       "historical       100\n",
       "entertainment    100\n",
       "business         100\n",
       "technologie      100\n",
       "sport            100\n",
       "space            100\n",
       "graphics         100\n",
       "medical          100\n",
       "Name: Details, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat['Details'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lufthansa flies back to profit',\n",
       " 'German airline Lufthansa has returned to profit in 2004 after posting huge losses in 2003.',\n",
       " 'In a preliminary report, the airline announced net profits of 400m euros ($527.61m; £274.73m), compared with a loss of 984m euros in 2003. Operating profits were at 380m euros, ten times more than in 2003. Lufthansa was hit in 2003 by tough competition and a dip in demand following the Iraq war and the killer SARS virus. It was also hit by troubles at its US catering business. Last year, Lufthansa showed signs of recovery even as some European and US airlines were teetering on the brink of bankruptcy. The board of Lufthansa has recommended paying a 2004 dividend of 0.30 euros per share. In 2003, shareholders did not get a dividend. The company said that it will give all the details of its 2004 results on 23 March.']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat.Info[0][:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Details</th>\n",
       "      <th>File Name</th>\n",
       "      <th>Info</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>politics</td>\n",
       "      <td>politics_153.txt</td>\n",
       "      <td>[Clarke to unveil immigration plan, New contro...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>sport</td>\n",
       "      <td>sport_70.txt</td>\n",
       "      <td>[Record fails to lift lacklustre meet, Yelena ...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>business</td>\n",
       "      <td>business_8.txt</td>\n",
       "      <td>[Weak dollar trims Cadbury profits, The world'...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>medical</td>\n",
       "      <td>medical_644.txt</td>\n",
       "      <td>[------------- cut here -----------------, Vol...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943</th>\n",
       "      <td>technologie</td>\n",
       "      <td>technologie_48.txt</td>\n",
       "      <td>[Startup Deploying AI Chatbots With “Conversat...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Details           File Name  \\\n",
       "623     politics    politics_153.txt   \n",
       "868        sport        sport_70.txt   \n",
       "78      business      business_8.txt   \n",
       "588      medical     medical_644.txt   \n",
       "943  technologie  technologie_48.txt   \n",
       "\n",
       "                                                  Info  Class  \n",
       "623  [Clarke to unveil immigration plan, New contro...      6  \n",
       "868  [Record fails to lift lacklustre meet, Yelena ...      8  \n",
       "78   [Weak dollar trims Cadbury profits, The world'...      0  \n",
       "588  [------------- cut here -----------------, Vol...      5  \n",
       "943  [Startup Deploying AI Chatbots With “Conversat...      9  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encode = LabelEncoder()\n",
    "df_cat['Class'] = label_encode.fit_transform(df_cat['Details'])\n",
    "df_cat.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert data into an array\n",
    "info_array = np.array(df_cat['Info'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert into tokens, remove stop words and stem the tokens\n",
    "tokenizer = RegexpTokenizer('[A-Za-z]\\w+')\n",
    "for idx in range(len(info_array)):   \n",
    "    info_array[idx] = tokenizer.tokenize(str(info_array[idx]))\n",
    "    \n",
    "info_array = [[ps.stem(token) for token in doc if token not in stop_words] for doc in info_array]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Details</th>\n",
       "      <th>File Name</th>\n",
       "      <th>Info</th>\n",
       "      <th>Class</th>\n",
       "      <th>Tokenized_Info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>historical</td>\n",
       "      <td>historical_46.txt</td>\n",
       "      <td>[World War II Ends (1945), At the Potsdam Conf...</td>\n",
       "      <td>4</td>\n",
       "      <td>[world, war, II, end, At, potsdam, confer, jul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>857</th>\n",
       "      <td>sport</td>\n",
       "      <td>sport_60.txt</td>\n",
       "      <td>[McIlroy wins 800m indoor title, James McIlroy...</td>\n",
       "      <td>8</td>\n",
       "      <td>[mcilroy, win, indoor, titl, jame, mcilroy, mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>politics</td>\n",
       "      <td>politics_15.txt</td>\n",
       "      <td>[Talks held on Gibraltar's future, Two days of...</td>\n",
       "      <td>6</td>\n",
       "      <td>[talk, held, gibraltar, futur, two, day, talk,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>sport</td>\n",
       "      <td>sport_11.txt</td>\n",
       "      <td>[Radcliffe yet to answer GB call, Paula Radcli...</td>\n",
       "      <td>8</td>\n",
       "      <td>[radcliff, yet, answer, GB, call, paula, radcl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>graphics</td>\n",
       "      <td>graphics_53.txt</td>\n",
       "      <td>[Hi:, I am digitizing a NTSC signal and displa...</td>\n",
       "      <td>3</td>\n",
       "      <td>[Hi, digit, ntsc, signal, display, PC, video, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>graphics</td>\n",
       "      <td>graphics_25.txt</td>\n",
       "      <td>[I require BGI drivers for Super VGA Displays ...</td>\n",
       "      <td>3</td>\n",
       "      <td>[requir, bgi, driver, super, vga, display, sup...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>business</td>\n",
       "      <td>business_2.txt</td>\n",
       "      <td>[Japanese growth grinds to a halt, Growth in J...</td>\n",
       "      <td>0</td>\n",
       "      <td>[japanes, growth, grind, halt, growth, japan, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>historical</td>\n",
       "      <td>historical_55.txt</td>\n",
       "      <td>[Algerian nationalism, 1954 film about French ...</td>\n",
       "      <td>4</td>\n",
       "      <td>[algerian, nation, film, french, algeria, both...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>sport</td>\n",
       "      <td>sport_67.txt</td>\n",
       "      <td>[Lewis-Francis eyeing world gold, Mark Lewis-F...</td>\n",
       "      <td>8</td>\n",
       "      <td>[lewi, franci, eye, world, gold, mark, lewi, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>graphics</td>\n",
       "      <td>graphics_1.txt</td>\n",
       "      <td>[\\t\\t\\tTuesday, June 22, 1993, \\t    Carderock...</td>\n",
       "      <td>3</td>\n",
       "      <td>[ttuesday, june, carderock, divis, naval, surf...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Details          File Name  \\\n",
       "441  historical  historical_46.txt   \n",
       "857       sport       sport_60.txt   \n",
       "621    politics    politics_15.txt   \n",
       "803       sport       sport_11.txt   \n",
       "349    graphics    graphics_53.txt   \n",
       "318    graphics    graphics_25.txt   \n",
       "12     business     business_2.txt   \n",
       "451  historical  historical_55.txt   \n",
       "864       sport       sport_67.txt   \n",
       "300    graphics     graphics_1.txt   \n",
       "\n",
       "                                                  Info  Class  \\\n",
       "441  [World War II Ends (1945), At the Potsdam Conf...      4   \n",
       "857  [McIlroy wins 800m indoor title, James McIlroy...      8   \n",
       "621  [Talks held on Gibraltar's future, Two days of...      6   \n",
       "803  [Radcliffe yet to answer GB call, Paula Radcli...      8   \n",
       "349  [Hi:, I am digitizing a NTSC signal and displa...      3   \n",
       "318  [I require BGI drivers for Super VGA Displays ...      3   \n",
       "12   [Japanese growth grinds to a halt, Growth in J...      0   \n",
       "451  [Algerian nationalism, 1954 film about French ...      4   \n",
       "864  [Lewis-Francis eyeing world gold, Mark Lewis-F...      8   \n",
       "300  [\\t\\t\\tTuesday, June 22, 1993, \\t    Carderock...      3   \n",
       "\n",
       "                                        Tokenized_Info  \n",
       "441  [world, war, II, end, At, potsdam, confer, jul...  \n",
       "857  [mcilroy, win, indoor, titl, jame, mcilroy, mo...  \n",
       "621  [talk, held, gibraltar, futur, two, day, talk,...  \n",
       "803  [radcliff, yet, answer, GB, call, paula, radcl...  \n",
       "349  [Hi, digit, ntsc, signal, display, PC, video, ...  \n",
       "318  [requir, bgi, driver, super, vga, display, sup...  \n",
       "12   [japanes, growth, grind, halt, growth, japan, ...  \n",
       "451  [algerian, nation, film, french, algeria, both...  \n",
       "864  [lewi, franci, eye, world, gold, mark, lewi, f...  \n",
       "300  [ttuesday, june, carderock, divis, naval, surf...  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat['Tokenized_Info']=info_array\n",
    "df_cat.sample(10)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Details</th>\n",
       "      <th>File Name</th>\n",
       "      <th>Info</th>\n",
       "      <th>Class</th>\n",
       "      <th>Tokenized_Info</th>\n",
       "      <th>Tokenized_Info_Details</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>business</td>\n",
       "      <td>business_1.txt</td>\n",
       "      <td>[Lufthansa flies back to profit, German airlin...</td>\n",
       "      <td>0</td>\n",
       "      <td>[lufthansa, fli, back, profit, german, airlin,...</td>\n",
       "      <td>lufthansa fli back profit german airlin luftha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>business_10.txt</td>\n",
       "      <td>[Winn-Dixie files for bankruptcy, US supermark...</td>\n",
       "      <td>0</td>\n",
       "      <td>[winn, dixi, file, bankruptci, US, supermarket...</td>\n",
       "      <td>winn dixi file bankruptci US supermarket group...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Details        File Name  \\\n",
       "0  business   business_1.txt   \n",
       "1  business  business_10.txt   \n",
       "\n",
       "                                                Info  Class  \\\n",
       "0  [Lufthansa flies back to profit, German airlin...      0   \n",
       "1  [Winn-Dixie files for bankruptcy, US supermark...      0   \n",
       "\n",
       "                                      Tokenized_Info  \\\n",
       "0  [lufthansa, fli, back, profit, german, airlin,...   \n",
       "1  [winn, dixi, file, bankruptci, US, supermarket...   \n",
       "\n",
       "                              Tokenized_Info_Details  \n",
       "0  lufthansa fli back profit german airlin luftha...  \n",
       "1  winn dixi file bankruptci US supermarket group...  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#replace , with space in token list\n",
    "df_cat['Tokenized_Info_Details'] = [ ' '.join(map(str,tok)) for tok in df_cat['Tokenized_Info']]\n",
    "\n",
    "df_cat.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(df_cat['Tokenized_Info_Details'].values,df_cat['Class'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((750,), (250,), (750,), (250,))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape,x_test.shape,y_train.shape,y_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'imag edit tip graphic design publish graphic design what imag edit whi import well us may know answer nowaday peopl click pictur everywher profession camera also smartphon camera who want look beauti everyon want look gorgeou want imag click look beauti pictur straight camera may look okay even okay expens camera perfect To make imag perfect imag edit post process necessari graphic design photoshop expert profession knowledg imag edit softwar like adob photoshop cc lightroom illustr etc most photograph also learn photoshop edit imag slow product photograph So today articl editor design also photograph speed edit process basic edit imag edit tip for graphic design and photograph the imag edit tip go talk today speed edit process focu import critic thing Of cours graphic design photoshop expert import thing edit photograph click pictur import edit the photo edit tip go share combin basic edit eas workflow So let get start without delay'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250,)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Form tf-idf vector\n",
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = [\"This is sports column\"]\n",
    "test_input = np.array(test_input)\n",
    "x_train_vector = vectorizer.fit_transform(x_train)\n",
    "x_test_vector =vectorizer.transform(x_test)\n",
    "test_vector = vectorizer.transform(test_input)\n",
    "pickle.dump(x_train, open(\"NB_train_data.npy\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((750, 16599), (250, 16599), (1, 16599))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_vector.shape, x_test_vector.shape,test_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['business', 'entertainment', 'food', 'graphics', 'historical', 'medical', 'politics', 'space', 'sport', 'technologie']\n"
     ]
    }
   ],
   "source": [
    "print(list(label_encode.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use multiple classifiers and grid search for prediction\n",
    "def sub_model(models, params, X_train, X_test, y_train, y_test):    \n",
    "    \n",
    "    if not set(models.keys()).issubset(set(params.keys())):\n",
    "        raise ValueError('parameters missing')\n",
    "\n",
    "    for key in models.keys():\n",
    "    \n",
    "        model = models[key]\n",
    "        param = params[key]\n",
    "        gs = GridSearchCV(model, param, cv=10, error_score=0, refit=True)\n",
    "        gs.fit(X_train, y_train)\n",
    "        y_pred = gs.predict(X_test)\n",
    "        \n",
    "        # Print scores for the classifier\n",
    "        print(key, ':', gs.best_params_)\n",
    "        print(\"Accuracy: %1.3f \\tPrecision: %1.3f \\tRecall: %1.3f \\t\\tF1: %1.3f\\n\" % (accuracy_score(y_test, y_pred), precision_score(y_test, y_pred, average='macro'), recall_score(y_test, y_pred, average='macro'), f1_score(y_test, y_pred, average='macro')))\n",
    "    \n",
    "    return gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing to make a pipeline \n",
    "models = {\n",
    "    'Naive Bayes': MultinomialNB(), \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#params\n",
    "params = {\n",
    "    'Naive Bayes': { 'alpha': [0.5, 1], 'fit_prior': [True, False] }, \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes : {'alpha': 0.5, 'fit_prior': True}\n",
      "Accuracy: 0.936 \tPrecision: 0.937 \tRecall: 0.937 \t\tF1: 0.932\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trained_model_NB = sub_model(models, params, x_train_vector, x_test_vector, y_train, y_test)\n",
    "## ML_modeling method also prints performance scores for each classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseEstimator.get_params of GridSearchCV(cv=10, error_score=0,\n",
       "             estimator=MultinomialNB(alpha=1.0, class_prior=None,\n",
       "                                     fit_prior=True),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'alpha': [0.5, 1], 'fit_prior': [True, False]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_model_NB.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the subject classification model:\n",
    "def vectorize(test_input):\n",
    "    #stem and  stop words\n",
    "    global vectorizer\n",
    "    stop_words = stopwords.words('english')\n",
    "    ps = PorterStemmer()\n",
    "    \n",
    "    #convert into tokens, remove stop words and stem the tokens\n",
    "    tokenizer = RegexpTokenizer('[A-Za-z]\\w+')\n",
    "    test_input = tokenizer.tokenize(str(test_input))\n",
    "    \n",
    "    test_input = [ps.stem(token) for token in test_input if token not in stop_words]      \n",
    "#     print(test_input)\n",
    "\n",
    "    test_input =  [' '.join(map(str,test_input))]\n",
    "    print(test_input)\n",
    "    test_input = np.array(test_input)\n",
    "#     print(test_input)\n",
    "    test_vector = vectorizer.transform(test_input)\n",
    "#     print(test_vector)    \n",
    "    \n",
    "    return test_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "virus spreading\n"
     ]
    }
   ],
   "source": [
    "test_input = \"virus spreading\"\n",
    "# test_input= test_input.replace('\"', ' ')\n",
    "print(type(test_input))\n",
    "print(test_input)\n",
    "\n",
    "# test_input = np.array(test_input)\n",
    "# print(test_input)\n",
    "# test_vector = vectorizer.transform(test_input)\n",
    "# print(test_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['viru spread']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([9]),\n",
       " array([[0.09653965, 0.08104756, 0.09881052, 0.07939591, 0.09255726,\n",
       "         0.0897472 , 0.09499243, 0.07741363, 0.0922975 , 0.19719834]]),\n",
       " 0.19719834287549579)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predict the subject classifiction\n",
    "test_vector= vectorize(test_input)\n",
    "y_pred = trained_model_NB.predict(test_vector)\n",
    "y_prob = trained_model_NB.predict_proba(test_vector)\n",
    "y_pred,y_prob,y_prob[0][np.argmax(y_prob)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['technologie']\n"
     ]
    }
   ],
   "source": [
    "# save the model to disk\n",
    "filename = 'NB_Model.sav'\n",
    "pickle.dump(trained_model_NB, open(filename, 'wb'))\n",
    " \n",
    "# some time later...\n",
    " \n",
    "# load the model from disk\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "result = loaded_model.predict(test_vector)\n",
    "print(label_encode.inverse_transform(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
